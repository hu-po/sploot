{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from lightglue import LightGlue, SuperPoint, DISK\n",
    "from lightglue.utils import load_image, rbd\n",
    "from lightglue import viz2d\n",
    "import torch\n",
    "import os\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "images = Path(\"assets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load extractor and matcher module\n",
    "In this example we use SuperPoint features combined with LightGlue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)  # load the extractor\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy example\n",
    "The top image shows the matches, while the bottom image shows the point pruning across layers. In this case, LightGlue prunes a few points with occlusions, but is able to stop the context aggregation after 4/9 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0 = load_image(\"/home/oop/dev/data/1c5fd88d-d6c0-4ca4-a731-4373f554e819_3of10.png\")\n",
    "image1 = load_image(\"/home/oop/dev/data/1c5fd88d-d6c0-4ca4-a731-4373f554e819_5of10.png\")\n",
    "image0 = load_image(\"/home/oop/dev/data/1c5fd88d-d6c0-4ca4-a731-4373f554e819_7of10.png\")\n",
    "\n",
    "feats0 = extractor.extract(image0.to(device))\n",
    "feats1 = extractor.extract(image1.to(device))\n",
    "matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "feats0, feats1, matches01 = [\n",
    "    rbd(x) for x in [feats0, feats1, matches01]\n",
    "]  # remove batch dimension\n",
    "\n",
    "kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.2)\n",
    "viz2d.add_text(0, f'Stop after {matches01[\"stop\"]} layers', fs=20)\n",
    "\n",
    "kpc0, kpc1 = viz2d.cm_prune(matches01[\"prune0\"]), viz2d.cm_prune(matches01[\"prune1\"])\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=[kpc0, kpc1], ps=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficult example\n",
    "For pairs with significant viewpoint- and illumination changes, LightGlue can exclude a lot of points early in the matching process (red points), which significantly reduces the inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0 = load_image(\"/home/oop/dev/data/1c5fd88d-d6c0-4ca4-a731-4373f554e819_3of10.png\")\n",
    "# image1 = load_image(\"/home/oop/dev/data/1c5fd88d-d6c0-4ca4-a731-4373f554e819_5of10.png\")\n",
    "image0 = load_image(\"/home/oop/dev/data/1c5fd88d-d6c0-4ca4-a731-4373f554e819_7of10.png\")\n",
    "\n",
    "feats0 = extractor.extract(image0.to(device))\n",
    "feats1 = extractor.extract(image1.to(device))\n",
    "matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "feats0, feats1, matches01 = [\n",
    "    rbd(x) for x in [feats0, feats1, matches01]\n",
    "]  # remove batch dimension\n",
    "\n",
    "kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.2)\n",
    "viz2d.add_text(0, f'Stop after {matches01[\"stop\"]} layers')\n",
    "\n",
    "kpc0, kpc1 = viz2d.cm_prune(matches01[\"prune0\"]), viz2d.cm_prune(matches01[\"prune1\"])\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=[kpc0, kpc1], ps=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kpts0)\n",
    "print(kpts1)\n",
    "print(\"kpts0\", kpts0.shape)\n",
    "print(\"kpts1\", kpts1.shape)\n",
    "\n",
    "print(\"matches\", matches)\n",
    "print(\"matches\", matches.shape)\n",
    "\n",
    "print(\"matches01\", matches01)\n",
    "print(\"matches01['matching_scores0']\", matches01[\"matching_scores0\"].shape)\n",
    "print(\"matches01['matching_scores1']\", matches01[\"matching_scores1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the matches from the first and second images\n",
    "match_indices0 = matches[:, 0]\n",
    "match_indices1 = matches[:, 1]\n",
    "\n",
    "# Use these indices to filter the matching_scores tensors\n",
    "matching_scores0 = matches01['matching_scores0'][match_indices0]\n",
    "matching_scores1 = matches01['matching_scores1'][match_indices1]\n",
    "\n",
    "# Print the filtered matching scores\n",
    "print(\"Filtered matching_scores0\", matching_scores0)\n",
    "print(\"Filtered matching_scores1\", matching_scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(matching_scores0.cpu().numpy(), matching_scores1.cpu().numpy(), alpha=0.5)\n",
    "\n",
    "# Set the axes limits\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Set the labels\n",
    "plt.xlabel('Matching Scores 0')\n",
    "plt.ylabel('Matching Scores 1')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the UUID\n",
    "uuid = \"1c5fd88d-d6c0-4ca4-a731-4373f554e819\"\n",
    "\n",
    "# Get all image paths in the data directory that match the pattern\n",
    "image_paths = sorted(list(Path(\"/home/oop/dev/data\").glob(f\"{uuid}*\")))\n",
    "\n",
    "# Iterate over all pairs of images\n",
    "for image_path1, image_path2 in itertools.combinations(image_paths, 2):\n",
    "    # Load the images\n",
    "    image1 = load_image(str(image_path1))\n",
    "    image2 = load_image(str(image_path2))\n",
    "\n",
    "    # Extract features and match\n",
    "    feats1 = extractor.extract(image1.to(device))\n",
    "    feats2 = extractor.extract(image2.to(device))\n",
    "    matches12 = matcher({\"image0\": feats1, \"image1\": feats2})\n",
    "    feats1, feats2, matches12 = [rbd(x) for x in [feats1, feats2, matches12]]\n",
    "\n",
    "    # Get keypoints and matches\n",
    "    kpts1, kpts2, matches = feats1[\"keypoints\"], feats2[\"keypoints\"], matches12[\"matches\"]\n",
    "    m_kpts1, m_kpts2 = kpts1[matches[..., 0]], kpts2[matches[..., 1]]\n",
    "\n",
    "    # Plot images and matches\n",
    "    axes = viz2d.plot_images([image1, image2])\n",
    "    viz2d.plot_matches(m_kpts1, m_kpts2, color=\"lime\", lw=0.2)\n",
    "    viz2d.add_text(0, f'Stop after {matches12[\"stop\"]} layers')\n",
    "\n",
    "    # Get the indices of the matches from the first and second images\n",
    "    match_indices0 = matches[:, 0]\n",
    "    match_indices1 = matches[:, 1]\n",
    "\n",
    "    # Use these indices to filter the matching_scores tensors\n",
    "    matching_scores0 = matches12['matching_scores0'][match_indices0]\n",
    "    matching_scores1 = matches12['matching_scores1'][match_indices1]\n",
    "\n",
    "\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(matching_scores0.cpu().numpy(), matching_scores1.cpu().numpy(), alpha=0.5)\n",
    "\n",
    "    # print out average matching score\n",
    "    print(\"Average matching score\", (matching_scores0.cpu().numpy() + matching_scores1.cpu().numpy()) / 2)\n",
    "\n",
    "\n",
    "    # Add the average matching score as a red dot\n",
    "    plt.scatter(\n",
    "        (matching_scores0.cpu().numpy() + matching_scores1.cpu().numpy()) / 2,\n",
    "        (matching_scores0.cpu().numpy() + matching_scores1.cpu().numpy()) / 2,\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "    # Set the axes limits\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "    # Set the labels\n",
    "    plt.xlabel('Matching Scores 0')\n",
    "    plt.ylabel('Matching Scores 1')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
